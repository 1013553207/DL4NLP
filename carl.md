#Counseling and Machine Learning
Carl is a project to train an autonomous agent to do text based chat counseling. It is like Siri or IBM Watson for counseling.  The idea is to use live counselors to chat with clients for short term sessions and record dialog data.  Then use this "training data" and machine learning (a subfield of artificial intelligence) to train an increasingly autonomous agent capable of chatting with and counseling clients.  

Carl is in the research phase and the biggest challenge is technical feasibility.  Is this possible?  Or will it be possible in the next few years?  This is passing the [Turing Test](https://en.wikipedia.org/wiki/Turing_test), where users can't distinguish a live person from a machine.  It was first [posed by Alan Turing in 1950](http://www.loebner.net/Prizef/TuringArticle.html) and it remains an elusive goal of computer science. I am going to outline two of the most challenging aspects and reasons for optimism. 

#Carl Rogers
The first challenge is gathering enough training data. The reason for optimism is the technique reflective listening pioneered by Carl Rogers.  I believe it is possible to train counselors using reflective listening in a way that is scalable and consistent. Because machine learning requires "big data" it will require many different counselors to create enough data. Current dialog research uses social media and movie and tv subtitle sources to train data. These sources are often in excess of one billion words, but suffer from an inconsistent voice.  I will explain reflective listening and how it enables a consistent voice.  

[Carl Rogers](https://en.wikipedia.org/wiki/Carl_Rogers) was a popular American psychologist.  He is a personal hero of mine. Carl Rogers believed if he could provide a relationship with empathy, non-judgement, positive regard, and authenticity it would enable the client to achieve a path of [self actualization](https://en.wikipedia.org/wiki/Self-actualization).  Self actualization is living up to your potential.  It means thinking less rigidly, seeing the world in less black and white terms.  It means being more realistic, more integrated and effective.  It means having higher frustration tolerance, and being more mature.  It means being less defensive, and more adaptive.  It means being less repressed in feeling, and more accepting.  Carl Rogers was very optimistic about human nature and he believed people have "a basically positive direction." Rogers said "The curious paradox is that when I accept myself just as I am, then I can change."  
(For more information see [this video where he describes and demonstrates his techniques](https://youtu.be/ee1bU4XuUyg?t=184) or Carl Roger's book [On becoming a person](http://www.amazon.com/On-Becoming-Person-Therapists-Psychotherapy/dp/039575531X))

The techniques include asking open ended questions.  Open ended questions are questions that can’t be answered with a yes or no response.  Examples of open ended questions are: 
- “What is on your mind?” 
- “How did you feel about that?” 
- "What was it like the first time you felt that way?"

Reflective listening also includes articulating the underlying emotion expressed by the client. The counselor may say “You seem frustrated” or “You seemed encouraged by that news.”  It is fundamentally an emotional classification problem.  

Reflective listening is not about giving advice.  If a client asks for direct advice like “What should I do?”  Counselors might respond with an open ended question like “What do you think your options are?”

Reflective listening is also non-directive, meaning they don’t lead the conversation.  Counselors also don’t disclose any personal information. If a client asks “Do you have kids?”  A counselor might respond with an open ended question like “What’s the reason you ask?” or try to summarize the underlying emotion  “You are concerned that someone who doesn't have kids won't be able to relate to you.”  

These techniques, while simple in concept, can be difficult in practice. The techniques are often counter-intutive many people's desire is to give advice, be directive and try to fix things for the client. Also, the results can be amazing.  When I was younger I had a counselor and after a session of complaining about my preacher, she said "You are desperately seeking strong male guidance and leadership."  Looking back it seems like a simple insight but for me it marked a profound change.  

My hypothesis is these techniques are scalable and consistent.  One counselor’s response shouldn’t conflict with another’s.  If you disclosed personal information like “I have two kids”  it would conflict with other counselors and not serve as consistent training data. Although there are concerns, because counselors have different personalities, vocabularies, genders, and other factors that could affect consistency.  The biggest challenge may be that although you don't disclose personal information, counselors often disclose their personal feelings or encouragement, like "I am sorry to hear that" or "You deserve better than that."  The degree and consistency of these disclosures is a possible challenge. In spite of these challenges, I think it is likely that counselors can be trained to have a consistent voice.  

A further reason for optimism is I believe it may possible to crowdsource the task of creating this data. Carl Rogers work was popular and accessible to non-professionals and he thought these techniques should be used in  interpersonal relationships in general. I have been trained in reflective listening techniques as a volunteer at the [crisis center](http://www.crisiscenterbham.com/), the national suicide prevention hotline, and [7 cups](http://www.7cups.com/). These counselors are not required to be licensed by the state but are instead called crisis counselors or listeners.  Although there are licensed counselors available for support, many of the volunteers at these places, like myself, are unlicensed lay people.  

#Machine Learning
The second challenge is the computer algorithms and the reason for optimism is the recent and ongoing advances in machine learning.  Machine learning has enabled many seemingly magical advances like speech recognition, and self driving cars. It powers NetFlix and Amazon recommendations. It identifies zip codes on letters at the post office, and amounts on checks at banks.  It matches drivers and passengers at Uber.  It identifies potential fraud at PayPal.  

Facebook and Google are using machine learning for many language related tasks like to [improve searches](http://searchengineland.com/faq-all-about-the-new-google-rankbrain-algorithm-234440), perform language translation, [create image captions for blind people](http://www.wired.com/2015/10/facebook-artificial-intelligence-describes-photo-captions-for-blind-people/), and create question answering agents and assistants, like [Facebook M](https://www.facebook.com/Davemarcus/posts/10156070660595195).  They are both releasing research and open source tools, like [TensorFlow](http://www.tensorflow.org/), and have a history of releasing [important proprietary research](http://infolab.stanford.edu/~backrub/google.html). They don’t seem to be  concerned with releasing the tools and research because they have other factors like infrastructure and data that will help them maintain their competitive advantages. The publicity from releasing tools and research also helps them recruit the best talent.  Some of these tools and research are also useful for the Carl project.  

One tool released by then Google researcher [Tomas Mikolov](https://scholar.google.com/citations?user=oBu8kMMAAAAJ&hl=en) and others in 2013 is [word2vec](https://code.google.com/p/word2vec/).  It is program that takes large bodies of text (ideally your training data) and it converts each word into a series of numbers called a vector. An important property of these numbers is that similar words have similar numbers.  For instance it knows that banana and pear are similar words. Encoding words into numbers is an important step because Machine learning uses math.  It is also able to perform analogies like: king - man + woman = queen.  This idea can also be extended to phrases. For example the numbers for "Los Angeles" are similar to the numbers for "San Francisco."  The idea can be extended further to sentences and paragraphs.  These are often called thought vectors. 

This functionality, detecting similarity and performing analogies, could form the basic building blocks of a system that is able to adaptively reuse dialog training data.  The system could find similar statements from clients using vector difference calculations and responses could change pronoun genders, verb tenses, and between singular and plural if needed using the analogy capabilities.

Google researchers Vinyals and Le released a research paper, [A neural conversation model](http://arxiv.org/pdf/1506.05869v3.pdf), where they train an agent using data from an internal tech support chat system, and data from Open Subtitles, which has movie and tv dialog for captioning. They use a framework called seq2seq that is originally designed to do machine translation.  It takes a single sentence like "What is the purpose of life?" and  it "translates" it to a single sentence response like "to serve the greater good." Incidentally, this response is from BattleStar Galatica.  This [research powers the Smart Reply feature](http://googleresearch.blogspot.co.uk/2015/11/computer-respond-to-this-email.html) for the Google Inbox app that presents users with several possible replies to emails.

Seq2Seq will work well for basic exchanges and greetings like "Thank you" and "You're welcome."  Seq2Seq might could be extended to more sentences and exchanges. However, a dialog system will likely require a more sophisticated ability to focus attention on relevant memory.  Memory and attention mechanisms are an [active topic of research](https://research.facebook.com/pages/764602597000662/reasoning-attention-memory-ram-nips-workshop-2015/).  There are several competing models like Memory Networks, Neural Turing machines, and Stack RNN.  
(For more technical information on the state of the art see [Deep learning for NLP](https://github.com/andrewt3000/DL4NLP#deep-learning-for-nlp-resources))

In reflective listening, you typically track the client's mood and emotion, so the requirements for memory are limited.  However context is needed to generate appropriate responses, like not asking questions the client has clearly answered, and not repeating counselor statements too often. These problems are not solved, and currently [very few researchers](https://www.uni-ulm.de/fileadmin/website_uni_ulm/allgemein/2015_iwsds/iwsds2015_submission_6.pdf) are working on them directly. However, researchers are working on them indirectly, seq2seq was designed for machine translation but is applicable to dialog systems. Also, QA systems with memory could help solve the problem of not asking an open ended question to which the answer is obvious.  

There will be some new concepts required. I am researching a novel concept that I call attention labeling. Consider this conversation. 
  
**Client:**  I love my husband, but he expects me to clean the house and never says thank you.  
**Counselor:** You feel unappreciated.  
  
The idea is to select "he expects me to clean the house and never says thank you" as the statement to which is being responded, and indicating the first part can be ignored. Obviously this will help train a system like seq2seq to not respond to "I love my husband" with "You feel unappreciated"  But the more interesting idea is to use this information to train an attention mechanism that preprocesses statements and reduce them to what warrants a response. This is a concept that I am actively researching and has challenges like ambiguity and scalability.  

In spite of the challenges and uncertainty, the resources being concentrated on these research problems and the open source nature of the machine learning community are grounds for optimism. There have been several AI hype cycles in the past, and it is possible we will see a decline in the AI hype cycle, however the gains are now to a point where I believe we are unlikely to enter a severe [AI winter](https://en.wikipedia.org/wiki/AI_winter) and some serious research and development will persist.   

In the short term, it is very likely that Carl could make suggested replies, like the previously mentioned smart reply feature, and could improve over time as more data is collected and more advanced machine learning algorithms are developed. Choosing between suggested responses,  also has the potential to help train counselors, and enable them to be more consistent and efficient.  

#Non-technical issues and implications
Many people find this idea abhorrent, they don't believe it will work because what makes counseling work is human connection. I see how it might seem impossible because  [genuine empathy and connection are what helps](https://www.youtube.com/watch?v=1Evwgu369Jw). But I believe it is uncertain, and worth trying. For me machine learning is collective intelligence, and a tool to connect with the contributors of the training data. There are also potential benefits, one [study](http://www.sciencedirect.com/science/article/pii/S0747563214002647) asserts that people have an increased willingness to disclose information to a computer. 

Another concern is privacy. That is a complicated issue, but here are a few ideas for consideration.  Carl Rogers was one of the first people to record counseling sessions for the purpose of research.  Another idea is to invert the current counseling model where you have confidentiality but not anonymity.  It might be easier to ensure anonymity rather than confidentiality.      
  
There are a lot of obstacles.  This is a moonshot.... swinging for the fences... likely to fail. But I think the potential benefits are mind boggling.  What if everyone in the world, speaking every language, at any time, had a place where they could be understood and accepted without judgment and was more capable of living up to their potential?

####Please share this link and contact me at [@andrewt3000](https://twitter.com/andrewt3000)
  




